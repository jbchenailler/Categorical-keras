{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "import tokenization\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.8.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hub.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('train_40k.csv', encoding='latin-1')\n",
    "test_data = pd.read_csv('val_10k.csv', encoding='latin-1')\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>productId</th>\n",
       "      <th>Title</th>\n",
       "      <th>userId</th>\n",
       "      <th>Helpfulness</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Text</th>\n",
       "      <th>Cat1</th>\n",
       "      <th>Cat2</th>\n",
       "      <th>Cat3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000E46LYG</td>\n",
       "      <td>Golden Valley Natural Buffalo Jerky</td>\n",
       "      <td>A3MQDNGHDJU4MK</td>\n",
       "      <td>0/0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>The description and photo on this product need...</td>\n",
       "      <td>grocery gourmet food</td>\n",
       "      <td>meat poultry</td>\n",
       "      <td>jerky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B000GRA6N8</td>\n",
       "      <td>Westing Game</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0/0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>860630400</td>\n",
       "      <td>This was a great book!!!! It is well thought t...</td>\n",
       "      <td>toys games</td>\n",
       "      <td>games</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000GRA6N8</td>\n",
       "      <td>Westing Game</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0/0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>883008000</td>\n",
       "      <td>I am a first year teacher, teaching 5th grade....</td>\n",
       "      <td>toys games</td>\n",
       "      <td>games</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000GRA6N8</td>\n",
       "      <td>Westing Game</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0/0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>897696000</td>\n",
       "      <td>I got the book at my bookfair at school lookin...</td>\n",
       "      <td>toys games</td>\n",
       "      <td>games</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00000DMDQ</td>\n",
       "      <td>I SPY A is For Jigsaw Puzzle 63pc</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2/4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>911865600</td>\n",
       "      <td>Hi! I'm Martine Redman and I created this puzz...</td>\n",
       "      <td>toys games</td>\n",
       "      <td>puzzles</td>\n",
       "      <td>jigsaw puzzles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    productId                                Title          userId  \\\n",
       "0  B000E46LYG  Golden Valley Natural Buffalo Jerky  A3MQDNGHDJU4MK   \n",
       "1  B000GRA6N8                         Westing Game         unknown   \n",
       "2  B000GRA6N8                         Westing Game         unknown   \n",
       "3  B000GRA6N8                         Westing Game         unknown   \n",
       "4  B00000DMDQ    I SPY A is For Jigsaw Puzzle 63pc         unknown   \n",
       "\n",
       "  Helpfulness  Score       Time  \\\n",
       "0         0/0    3.0         -1   \n",
       "1         0/0    5.0  860630400   \n",
       "2         0/0    5.0  883008000   \n",
       "3         0/0    5.0  897696000   \n",
       "4         2/4    5.0  911865600   \n",
       "\n",
       "                                                Text                  Cat1  \\\n",
       "0  The description and photo on this product need...  grocery gourmet food   \n",
       "1  This was a great book!!!! It is well thought t...            toys games   \n",
       "2  I am a first year teacher, teaching 5th grade....            toys games   \n",
       "3  I got the book at my bookfair at school lookin...            toys games   \n",
       "4  Hi! I'm Martine Redman and I created this puzz...            toys games   \n",
       "\n",
       "           Cat2            Cat3  \n",
       "0  meat poultry           jerky  \n",
       "1         games         unknown  \n",
       "2         games         unknown  \n",
       "3         games         unknown  \n",
       "4       puzzles  jigsaw puzzles  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "label = preprocessing.LabelEncoder()\n",
    "y = label.fit_transform(train_data['Score'])\n",
    "y = to_categorical(y)\n",
    "\n",
    "ytest = label.transform(test_data['Score'])\n",
    "ytest = to_categorical(ytest)\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]]\n",
      "(40000, 6)\n"
     ]
    }
   ],
   "source": [
    "input_cat = preprocessing.LabelEncoder()\n",
    "cat_x = input_cat.fit_transform(train_data['Cat1'])\n",
    "cat_x = to_categorical(cat_x)\n",
    "\n",
    "cat_xtest = input_cat.transform(test_data['Cat1'])\n",
    "cat_xtest = to_categorical(cat_xtest)\n",
    "\n",
    "print(cat_x[:5])\n",
    "print(cat_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2'\n",
    "bert_layer = hub.KerasLayer(m_url, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\n",
    "\n",
    "def bert_encode(texts, tokenizer, max_len=512):\n",
    "    all_tokens = []\n",
    "    all_masks = []\n",
    "    all_segments = []\n",
    "    \n",
    "    for text in texts:\n",
    "        text = tokenizer.tokenize(text)\n",
    "        \n",
    "        text = text[:max_len-2]\n",
    "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
    "        pad_len = max_len-len(input_sequence)\n",
    "        \n",
    "        tokens = tokenizer.convert_tokens_to_ids(input_sequence) + [0] * pad_len\n",
    "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
    "        segment_ids = [0] * max_len\n",
    "        \n",
    "        all_tokens.append(tokens)\n",
    "        all_masks.append(pad_masks)\n",
    "        all_segments.append(segment_ids)\n",
    "        \n",
    "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(bert_layer,Cat_X, max_len=512):\n",
    "    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "    segment_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
    "    \n",
    "    Input_cat_X = tf.keras.Input(shape=(cat_x.shape[1],),dtype=tf.float32,name=\"Input_cat_X\")\n",
    "\n",
    "    pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "    \n",
    "    \n",
    "\n",
    "    clf_output = sequence_output[:, 0, :] # keeping only the CLS term\n",
    "\n",
    "    merge = tf.keras.layers.concatenate([clf_output,Input_cat_X],axis=1)\n",
    "\n",
    "\n",
    "    lay = tf.keras.layers.Dense(256, activation='relu')(merge)\n",
    "    lay = tf.keras.layers.Dropout(0.2)(lay)\n",
    "    lay = tf.keras.layers.Dense(128, activation='relu')(lay)\n",
    "    lay = tf.keras.layers.Dropout(0.2)(lay)\n",
    "    lay = tf.keras.layers.Dense(32, activation='relu')(lay)\n",
    "    lay = tf.keras.layers.Dropout(0.2)(lay)\n",
    "    out = tf.keras.layers.Dense(5, activation='softmax')(lay)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=[input_word_ids, input_mask, segment_ids,Input_cat_X], outputs=out)\n",
    "    model.compile(tf.keras.optimizers.Adam(lr=2e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 60\n",
    "train_input = bert_encode(train_data.Text.values, tokenizer, max_len=max_len)\n",
    "test_input = bert_encode(test_data.Text.values, tokenizer, max_len=max_len)\n",
    "train_labels = y\n",
    "test_label = ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3. 4. 5.]\n"
     ]
    }
   ],
   "source": [
    "labels = label.classes_\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_word_ids (InputLayer)     [(None, 60)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 60)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 60)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer (KerasLayer)        [(None, 768), (None, 109482241   input_word_ids[0][0]             \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem (Slici (None, 768)          0           keras_layer[0][1]                \n",
      "__________________________________________________________________________________________________\n",
      "Input_cat_X (InputLayer)        [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 774)          0           tf.__operators__.getitem[0][0]   \n",
      "                                                                 Input_cat_X[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          198400      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          32896       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           4128        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 5)            165         dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 109,717,830\n",
      "Trainable params: 109,717,829\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jean-Baptiste\\.conda\\envs\\PythonGPUFPI\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = build_model(bert_layer,cat_x, max_len=max_len)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2000/2000 [==============================] - 169s 80ms/step - loss: 0.9811 - accuracy: 0.6297 - val_loss: 0.8197 - val_accuracy: 0.6865\n",
      "Epoch 2/2\n",
      "2000/2000 [==============================] - 160s 80ms/step - loss: 0.8233 - accuracy: 0.6861 - val_loss: 0.8284 - val_accuracy: 0.6859\n"
     ]
    }
   ],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('modelreview.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2, verbose=1)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\", histogram_freq=1)\n",
    "\n",
    "l = list(train_input)\n",
    "l.append(cat_x)\n",
    "\n",
    "train_sh = model.fit(\n",
    "    l, train_labels,     validation_split=0.2,  #callbacks=[checkpoint, earlystopping,tensorboard_callback], \n",
    "    epochs=2,\n",
    "    batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 14s 43ms/step - loss: 0.7464 - accuracy: 0.7206\n",
      "[0.746426522731781, 0.7206000089645386]\n"
     ]
    }
   ],
   "source": [
    "ltest = list(test_input)\n",
    "ltest.append(cat_xtest)\n",
    "import keras\n",
    "print(model.evaluate(ltest,ytest))\n",
    "\n",
    "#custom_objects = {\"KerasLayer\": bert_layer}\n",
    "#model_load = keras.models.load_model(\"modelreview.h5\",custom_objects)\n",
    "#model_load.evaluate(ltest,ytest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('PythonGPUFPI')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c73a36446519fbd64fcb1e87c5b1bf4fefaedcb144f88c28d8f7e79fc6c5fcda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
